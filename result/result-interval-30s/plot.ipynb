{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RED = '\\033[31m'\n",
    "GREEN = '\\033[32m'\n",
    "YELLOW = '\\033[33m'\n",
    "BLUE = '\\033[34m'\n",
    "MAGENTA = '\\033[35m'\n",
    "CYAN = '\\033[36m'\n",
    "WHITE = '\\033[37m'\n",
    "RESET = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_subdirectory_names(directory):\n",
    "    subdirectory_names = []\n",
    "    # 使用 os.walk 递归遍历目录树\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for dir_name in dirs:\n",
    "            print(dir_name)\n",
    "            subdirectory_names.append(dir_name)\n",
    "    \n",
    "    return subdirectory_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_subdirectory_names(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scale_factor(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "    for line in lines:\n",
    "        if \"sf =\" in line:\n",
    "            sf = int(line.split(\"=\")[1].strip())\n",
    "            return sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(s:str)->dict:\n",
    "    info = dict()\n",
    "    time_pattern = re.compile(r'Time\\[(\\d+\\.\\d+)ms\\]')\n",
    "    id_pattern = re.compile(r'Job\\[\\s*(\\d+)\\]')\n",
    "\n",
    "\n",
    "    info[\"job_id\"] = int(re.findall(\"\\[(.*?)\\]\",s,re.I|re.M)[1])\n",
    "    info[\"time\"] = float(re.findall(\"\\[(.*?)\\]\",s,re.I|re.M)[0].split()[0])\n",
    "    info[\"event\"] = s.split(\",\")[1].strip()\n",
    "\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_num(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    lines = [extract_info(line) for line in lines if line.startswith(\"DEBUG\")]\n",
    "    return int(len(lines) / 3) , lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_event_time(job_id:int,event:str,lines:list,scale_factor):\n",
    "    for line in lines:\n",
    "        if line[\"job_id\"] == job_id and line[\"event\"] == event:\n",
    "            return float(line[\"time\"]) * scale_factor / 1000\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(sched_name:str, scale_factor):\n",
    "    filename = os.path.join(sched_name, \"res.csv\")\n",
    "    job_num, lines = get_job_num(filename)\n",
    "    #print(lines)\n",
    "    jobs = dict()\n",
    "    jct_sum = list()\n",
    "    exec_time_list = list()\n",
    "    for job_id in range(job_num):\n",
    "        arrive_time = get_job_event_time(job_id,\"ARRIVE\",lines,scale_factor)\n",
    "        #print(arrive_time) \n",
    "        place_time  = get_job_event_time(job_id,\"START\", lines,scale_factor)\n",
    "        end_time    = get_job_event_time(job_id,\"END\",   lines,scale_factor)\n",
    "        jobs[job_id] = {\n",
    "            \"arrive_time\":arrive_time,\n",
    "            \"place_time\":place_time,\n",
    "            \"end_time\":end_time,\n",
    "            \"pend_time\":place_time - arrive_time,\n",
    "            \"exec_time\":end_time - place_time\n",
    "        }\n",
    "        #print(job_id,\"%.2f\" % (end_time - arrive_time))\n",
    "        jct_sum.append(end_time - arrive_time)\n",
    "        exec_time_list.append(float(\"%.2f\" % (end_time - arrive_time)))\n",
    "        ave_jct = np.mean(np.array((jct_sum)))\n",
    "    tmp = [float(\"%.2f\" % i) for i in jct_sum]\n",
    "    # print(\"JCT\", tmp)\n",
    "    # print(\"EXEC\", exec_time_list)\n",
    "    print(\"*\" * 40)\n",
    "    print(f\"{YELLOW}Schedule name: %s{RESET}\" % sched_name)\n",
    "    print(f\"{GREEN}Ave JCT: %.2f{RESET}\" % (sum(jct_sum) / job_num))\n",
    "    print(f\"{GREEN}95%%-th JCT: %.2f{RESET}\" % np.percentile(jct_sum, 95))\n",
    "    print(f\"{GREEN}Makespan: %.2f{RESET}\" % (float(lines[-1][\"time\"] - lines[0][\"time\"]) * scale_factor / 1000))\n",
    "    return jobs, sum(jct_sum) / job_num, np.percentile(jct_sum, 95), (lines[-1][\"time\"] - lines[0][\"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prefix_sum(lst, loc):\n",
    "    sum = 0\n",
    "    for i in range(len(lst)):\n",
    "        if i < loc:\n",
    "            sum += lst[i]\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tiny_bar_config(dirname, job_num, place_list, scale_factor):\n",
    "    bar_list = list()\n",
    "    \n",
    "    tput_file = os.listdir(dirname)\n",
    "    \n",
    "    tput_file = [os.path.join(dirname, filename) for filename in tput_file if filename.split(\".\")[-1] == \"txt\" and int(filename.split(\"-\")[1]) in list(range(job_num))]\n",
    "   \n",
    "    for file in tput_file:\n",
    "        with open(file, \"r\") as f:\n",
    "            job_id = int(file.split(\"-\")[-2])\n",
    "            lines = f.readlines()\n",
    "            tput_list = list()\n",
    "            height_list = list()\n",
    "            for line in lines:\n",
    "                tput_list.append(float(line.split(\",\")[1]) * scale_factor / 1000)\n",
    "            for i,line in enumerate(lines):\n",
    "                bottom = place_list[job_id] + prefix_sum(tput_list, i)\n",
    "                height = tput_list[i] \n",
    "                if max(tput_list) == min(tput_list):\n",
    "                    color = plt.cm.viridis(1 - (height - min(tput_list)) / min(tput_list))\n",
    "                else:\n",
    "                    color = plt.cm.viridis(1 - (height - min(tput_list)) / (max(tput_list) - min(tput_list)))\n",
    "\n",
    "                bar_list.append({\n",
    "                    \"job_id\": job_id,\n",
    "                    \"bottom\": bottom,\n",
    "                    \"height\":height,\n",
    "                    \"color\": color\n",
    "                })\n",
    "    return bar_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlabel_dict = {    \n",
    "    \"fifo-load_balance\":\"Kubernetes\",\n",
    "\n",
    "    \"fifo-consolidate\":\"Yarn\", \n",
    "    \n",
    "    \"jaca-jaca\":\"jaca\",\n",
    "    \n",
    "    \"smallest-tiresias\":\"GPU-Te\",\n",
    "    \"fifo-tiresias\":\"Arr-Te\",\n",
    "    \"time-shortest-tiresias\":\"Time-Te\",\n",
    "    \"gputime-shortest-tiresias\":\"GT-Te\",\n",
    "    \n",
    "    \"fifo-gandiva\":\"gandiva\",\n",
    "}\n",
    "sched_list = get_all_subdirectory_names(\".\")\n",
    "sched_list = [sched for sched in sched_list if sched in list(xlabel_dict.keys())]\n",
    "#sched_list = [\"jaca-jaca\"]\n",
    "sched_dict = {i:v for i,v in enumerate(sched_list)}\n",
    "#sched_list = [sched_list[0]]\n",
    "print(sched_list)\n",
    "\n",
    "jct_dict = dict()\n",
    "jct_dict_95 = dict()\n",
    "makespan_list = dict()\n",
    "scale_factor = get_scale_factor(\"../../run.py\")\n",
    "for sched in sched_list:\n",
    "    jobs_info, ave_jct, jct_95, makespan = main(sched,scale_factor)\n",
    "    jct_dict[sched] = ave_jct\n",
    "    jct_dict_95[sched] = jct_95\n",
    "    makespan_list[sched] = makespan\n",
    "    #continue\n",
    "    arrive_list = [v[\"arrive_time\"] for k,v in jobs_info.items()]\n",
    "    pend_list   = [v[\"pend_time\"]   for k,v in jobs_info.items()]\n",
    "    exec_list   = [v[\"exec_time\"]   for k,v in jobs_info.items()]\n",
    "    place_list  = [v[\"place_time\"]  for k,v in jobs_info.items()]\n",
    "    plt.cla()\n",
    "    plt.style.use(\"fivethirtyeight\")\n",
    "    plt.bar(range(len(jobs_info)), pend_list, bottom=arrive_list, color = \"#B8DBB3\", label = \"pending\")\n",
    "    # bar_list = make_tiny_bar_config(sched, len(arrive_list), place_list, scale_factor)\n",
    "    # # plt.bar(range(len(jobs_info)), exec_list, bottom=place_list,  color = \"#E29135\", label = \"running\")\\\n",
    "    # for bar in bar_list:\n",
    "    #     plt.bar([bar[\"job_id\"]],[bar[\"height\"]],bottom=[bar[\"bottom\"]],color = bar[\"color\"])\n",
    "    \n",
    "    #plt.text(7, 20000, \"the deeper color, the slower\", fontsize=12, color='red')\n",
    "    plt.title(sched)\n",
    "    plt.xticks(range(len(jobs_info)), fontsize=4)\n",
    "    plt.xlabel(\"Job id\")\n",
    "    plt.ylabel(\"Time (s)\")\n",
    "    plt.legend()\n",
    "    plt.savefig(\"%s/res.pdf\" % sched, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_res(filename, xlabel_dict, res_list):\n",
    "    with open(filename, \"w\") as f:\n",
    "        for sched_name, v in zip(list(xlabel_dict.values()), res_list):\n",
    "            f.write(f\"{sched_name},{v}\\n\")\n",
    "\n",
    "xlabel_dict = {i:xlabel_dict[v] for i,v in enumerate(sched_list)}\n",
    "print(xlabel_dict)\n",
    "# JCT\n",
    "plt.cla()\n",
    "plt.title(\"JCT comparision\")\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "\n",
    "uniform_value = np.array(list(jct_dict.values())) / min(jct_dict.values())\n",
    "plt.bar(range(len(jct_dict)), uniform_value)\n",
    "plt.xlabel(\"Sched + Placer\")\n",
    "plt.xticks(list(xlabel_dict.keys()),list(xlabel_dict.values()),rotation = 90, fontsize = 14)\n",
    "\n",
    "write_res(\"jct.csv\", xlabel_dict, uniform_value)\n",
    "\n",
    "plt.savefig(\"jct.pdf\", bbox_inches = \"tight\")\n",
    "\n",
    "# 95th JCT\n",
    "plt.cla()\n",
    "plt.title(\"JCT-95th comparision\")\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "\n",
    "uniform_value = np.array(list(jct_dict_95.values())) / min(jct_dict_95.values())\n",
    "plt.bar(range(len(jct_dict_95)),uniform_value)\n",
    "plt.xlabel(\"Sched + Placer\")\n",
    "plt.xticks(list(xlabel_dict.keys()),list(xlabel_dict.values()),rotation = 90, fontsize = 14)\n",
    "write_res(\"jct-95th.csv\", xlabel_dict, uniform_value)\n",
    "plt.savefig(\"jct-95th.pdf\", bbox_inches = \"tight\")\n",
    "\n",
    "# Makespan\n",
    "plt.cla()\n",
    "plt.title(\"Makespan comparision\")\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "\n",
    "uniform_value = np.array(list(makespan_list.values())) / min(makespan_list.values())\n",
    "plt.bar(range(len(makespan_list)),uniform_value)\n",
    "plt.xlabel(\"Sched + Placer\")\n",
    "plt.xticks(list(xlabel_dict.keys()),list(xlabel_dict.values()),rotation = 90, fontsize = 14)\n",
    "\n",
    "write_res(\"makespan.csv\", xlabel_dict, uniform_value)\n",
    "plt.savefig(\"makespan.pdf\", bbox_inches = \"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
